{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad759012",
   "metadata": {},
   "source": [
    "### Which Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799c8352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cde77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\protos\\service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Setup MlFlow Tracking Server\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b3c9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/08b3d1adff6243278b669a49a999e16b', creation_time=1766684040567, experiment_id='3', last_update_time=1766684040567, lifecycle_stage='active', name='Experiment-2: BoW v/s TfIdf', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or Create an experiment\n",
    "mlflow.set_experiment(\"Experiment-2: BoW v/s TfIdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61bde8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d450ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36662, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24768</th>\n",
       "      <td>god dammit mad respect guy guy fucking gem act...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31992</th>\n",
       "      <td>hello frands chai peelo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16533</th>\n",
       "      <td>allegedly</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24482</th>\n",
       "      <td>funny part dev root word devil mobile get link...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>not time leave think progress like removing ve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "24768  god dammit mad respect guy guy fucking gem act...        -1\n",
       "31992                            hello frands chai peelo         0\n",
       "16533                                          allegedly        -1\n",
       "24482  funny part dev root word devil mobile get link...         1\n",
       "1101   not time leave think progress like removing ve...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./artifacts/reddit_preprocessing.csv\").dropna(subset=['clean_comment'])\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020522c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ARTIFACT_DIR = \"artifacts\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae29d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the experiment\n",
    "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
    "    \n",
    "    # Vectorization\n",
    "    if vectorizer_type == \"BoW\":\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
    "\n",
    "    # Split the data into train and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Define and train a Random Forest model\n",
    "    with mlflow.start_run() as run:\n",
    "        # Set tags for the experiment and run\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
    "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "        # Add a description\n",
    "        mlflow.set_tag(\"description\", f\"Random Forest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
    "\n",
    "        # Log Vectorizer parameters\n",
    "        mlflow.log_param(\"vectorizer_type: \", vectorizer_type)\n",
    "        mlflow.log_param(\"ngram_range: \", ngram_range)\n",
    "        mlflow.log_param(\"vectorizer_max_features: \", vectorizer_max_features)\n",
    "\n",
    "        # Log Random Forest parameters\n",
    "        n_estimators = 200\n",
    "        max_depth = 15\n",
    "\n",
    "        mlflow.log_param(\"n_estimators: \", n_estimators)\n",
    "        mlflow.log_param(\"max_depth: \", max_depth)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions and log metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Accuracy: \", accuracy)\n",
    "\n",
    "        # Log Classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != \"support\":\n",
    "                        mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log Confusion Matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
    "\n",
    "        # Save and log the confusion matrix plot\n",
    "        filename = f\"Exp2_{vectorizer_name}_{ngram_range}_ConfusionMatrix.png\"\n",
    "        cm_path = os.path.join(ARTIFACT_DIR, filename)\n",
    "        plt.savefig(cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"Random_Forest_Model_{vectorizer_name}_{ngram_range}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7723fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/26 01:38:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 01:39:48 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 01:40:56 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 01:41:55 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 01:43:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 01:44:07 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "# Run experiments for BoW and TF-IDF with different n-grams\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]     # unigrams, bigrams, trigrams\n",
    "max_features = 5000\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    # BoW Experiments\n",
    "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
    "\n",
    "    # TF-IDF Experiments\n",
    "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9988c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
