{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03801530",
   "metadata": {},
   "source": [
    "### How many max features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061ca598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf1b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\protos\\service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Setup MLFlow Tracking Server\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7187b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/26 13:30:20 INFO mlflow.tracking.fluent: Experiment with name 'Expr 3- TFIDF Trigram max features' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/bf26a879d5224a2a8c45bf2ed05e7792', creation_time=1766736019531, experiment_id='4', last_update_time=1766736019531, lifecycle_stage='active', name='Expr 3- TFIDF Trigram max features', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or Create an experiment\n",
    "mlflow.set_experiment(\"Expr 3- TFIDF Trigram max features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb083e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113b4880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36662, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>bhug</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15556</th>\n",
       "      <td>effortlessly karmawhoring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>let raise glass defend freedom paid ultimate p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>modi watch south park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16144</th>\n",
       "      <td>charged folk india month subscribe billion peo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "9740                                                bhug         0\n",
       "15556                          effortlessly karmawhoring         0\n",
       "14633  let raise glass defend freedom paid ultimate p...         0\n",
       "1735                               modi watch south park         0\n",
       "16144  charged folk india month subscribe billion peo...         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./artifacts/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8ca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ARTIFACT_DIR = \"artifacts\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac88438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the experiment\n",
    "def run_experiment_tfidf_max_features(max_features):\n",
    "    ngram_range = (1, 3)    # Trigram setting\n",
    "\n",
    "    # Vectorization using TF-IDF with varying max_features\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Define and train a Random Forest Model\n",
    "    with mlflow.start_run() as run:\n",
    "        # Set tags for the experiment and run\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"TFIDF_Trigram_max_features_{max_features}\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
    "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "        # Add a descripion\n",
    "        mlflow.set_tag(\"description\", f\"Random Forest with TF-IDF Trigrams, max_features={max_features}\")\n",
    "\n",
    "         # Log Vectorizer parameters\n",
    "        mlflow.log_param(\"vectorizer_type: \", \"TF-IDF\")\n",
    "        mlflow.log_param(\"ngram_range: \", ngram_range)\n",
    "        mlflow.log_param(\"vectorizer_max_features: \", max_features)\n",
    "\n",
    "        # Log Random Forest parameters\n",
    "        n_estimators = 200\n",
    "        max_depth = 15\n",
    "\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions and log metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Accuracy: \", accuracy)\n",
    "\n",
    "        # Log Classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != \"support\":\n",
    "                        mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log Confusion Matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, max_features={max_features}\")\n",
    "\n",
    "        # Save and log the confusion matrix plot\n",
    "        filename = f\"Exp3_TF_IDF_Trigrams{max_features}_ConfusionMatrix.png\"\n",
    "        cm_path = os.path.join(ARTIFACT_DIR, filename)\n",
    "        plt.savefig(cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"Random_Forest_Model_TF_IDF_Trigrams_{max_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec6d37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/26 13:58:17 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 13:59:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 13:59:46 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:01:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:01:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:03:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:04:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:05:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:06:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 14:07:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "# Test various max_features values\n",
    "max_features_values = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "for max_features in max_features_values:\n",
    "    run_experiment_tfidf_max_features(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f4120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
