{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016bb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library for numerical operations\n",
    "import numpy as np\n",
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de851311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from the specified URL into a pandas DataFrame\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
    "# Print the shape (number of rows and columns) of the DataFrame\n",
    "print(df.shape)\n",
    "# Display the first 5 rows of the DataFrame to inspect the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe15bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a concise summary of the DataFrame, including index dtype, column dtypes, non-null values, and memory usage\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd077513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 3 records from the 'clean_comment' column and return their values as a numpy array\n",
    "df.sample(3)['clean_comment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4495dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of missing (null) values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f38c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and display rows where the 'clean_comment' column has missing values (NaN)\n",
    "df[df['clean_comment'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196e1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with missing 'clean_comment' and count the unique values in the 'category' column for these rows\n",
    "df[df['clean_comment'].isna()]['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bee98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and display rows where the 'category' column has missing values (NaN)\n",
    "df[df['category'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "483edf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values from the DataFrame in place\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6495b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame after dropping null values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d63784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of duplicate rows in the DataFrame\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d63c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the rows that are duplicates\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23b1e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for duplicate rows and count the occurrences of each unique row among the duplicates\n",
    "df[df.duplicated()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23b1e913-new",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the counts of all unique rows\n",
    "counts = df.value_counts()\n",
    "# Filter to keep only those rows that appear more than once (duplicates)\n",
    "duplicates_with_counts = counts[counts > 1]\n",
    "# Print the duplicates with their total counts\n",
    "print(duplicates_with_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84974fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame in place\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7c556ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are no more duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fccfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and display rows where 'clean_comment' is an empty string after stripping whitespace\n",
    "df[df['clean_comment'].str.strip()=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ec140aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only rows where 'clean_comment' is NOT an empty string after stripping whitespace\n",
    "df = df[~(df['clean_comment'].str.strip()=='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regex-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Define an exhaustive regex pattern to match URLs (http, https, ftp, www, etc.)\n",
    "url_pattern = r'(?i)\\b((?:https?://|ftp://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n",
    "\n",
    "# Check for rows containing URLs in the 'clean_comment' column\n",
    "rows_with_urls = df[df['clean_comment'].str.contains(url_pattern, regex=True, na=False)]\n",
    "\n",
    "# Print the number of rows with URLs\n",
    "print(f\"Number of rows with URLs: {len(rows_with_urls)}\")\n",
    "# Display the rows containing URLs\n",
    "print(rows_with_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remove-newline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace new line characters ('\\n') with a space in the 'clean_comment' column to preserve word separation\n",
    "df['clean_comment'] = df['clean_comment'].str.replace(r'\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0aa70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
