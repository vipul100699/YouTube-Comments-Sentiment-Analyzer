{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58468a08",
   "metadata": {},
   "source": [
    "### Hndling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a874d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e7e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\protos\\service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Setup MLFlow Tracking Server\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81263f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/bd78764ab56b4fa4b20d1a901a8de44e', creation_time=1766739441185, experiment_id='5', last_update_time=1766739441185, lifecycle_stage='active', name='Exr 4- Handling Imbalanced Data', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or Create an experiment\n",
    "mlflow.set_experiment(\"Exr 4- Handling Imbalanced Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d82156a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f33c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36662, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>appeasement didi not anything votebank rahul k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31984</th>\n",
       "      <td>lmao hysterical</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15675</th>\n",
       "      <td>becoming like chinese dictatorship</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>people section indeed affected rich lost money...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>pretty much clear people india definitely not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "10673  appeasement didi not anything votebank rahul k...         1\n",
       "31984                                    lmao hysterical        -1\n",
       "15675                 becoming like chinese dictatorship         1\n",
       "24401  people section indeed affected rich lost money...         1\n",
       "5494   pretty much clear people india definitely not ...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./artifacts/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77018c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ARTIFACT_DIR = \"artifacts\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40b114",
   "metadata": {},
   "source": [
    "### Techiniques Used are Class_Weights, OverSampling, ADASYN, UnderSampling, SMOTE_ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eecae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the experiment\n",
    "def run_imbalanced_experiment(imbalance_method):\n",
    "    ngram_range = (1, 3)    # Trigram setting\n",
    "    max_features = 1000\n",
    "\n",
    "    # Split the data into training and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Vectorization using TF-IDF, fit on training data only\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)     # Fit on training data\n",
    "    X_test_vec = vectorizer.transform(X_test)       # Transform test data\n",
    "\n",
    "    # Handle class imbalance based on the selected method (only applied to the training set)\n",
    "    if imbalance_method == 'class_weights':\n",
    "        # Use class_weight in Random Forest\n",
    "        class_weight = 'balanced'\n",
    "    else:\n",
    "        class_weight = 'None'   # Do not apply class_weight if using resampling\n",
    "\n",
    "        # Resampling Techniques (only applied to the training dataset)\n",
    "        if imbalance_method == 'oversampling':\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'adasyn':\n",
    "            adasyn = ADASYN(random_state=42)\n",
    "            X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'undersampling':\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train_vec, y_train = rus.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'smote_enn':\n",
    "            smote_enn = SMOTEENN(random_state=42)\n",
    "            X_train_vec, y_train = smote_enn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "    # Define and train a RandomForest model\n",
    "    with mlflow.start_run() as run:\n",
    "        # Set tags for the experiment and run\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"Imbalance_{imbalance_method}_RandomForest_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"imbalance_handling\")\n",
    "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "        # Add a descripion\n",
    "        mlflow.set_tag(\"description\", f\"Random Forest with TF-IDF Trigrams, imbalance handling method= {imbalance_method}\")\n",
    "\n",
    "         # Log Vectorizer parameters\n",
    "        mlflow.log_param(\"vectorizer_type: \", \"TF-IDF\")\n",
    "        mlflow.log_param(\"ngram_range: \", ngram_range)\n",
    "        mlflow.log_param(\"vectorizer_max_features: \", max_features)\n",
    "\n",
    "        # Log Random Forest parameters\n",
    "        n_estimators = 200\n",
    "        max_depth = 15\n",
    "\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "        # Make predictions and log metrics\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "\n",
    "        # Log Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Accuracy: \", accuracy)\n",
    "\n",
    "        # Log Classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != \"support\":\n",
    "                        mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log Confusion Matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, Imbalance={imbalance_method}\")\n",
    "\n",
    "        # Save and log the confusion matrix plot\n",
    "        filename = f\"Exp4_TF_IDF_Trigrams_{imbalance_method}_ConfusionMatrix.png\"\n",
    "        cm_path = os.path.join(ARTIFACT_DIR, filename)\n",
    "        plt.savefig(cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"Random_Forest_Model_TF_IDF_Trigrams_imbalance_{imbalance_method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd45048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/26 17:19:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 17:21:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 17:23:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 17:24:07 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "e:\\Machine Learning\\YouTube_Comment_Analyzer\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025/12/26 17:28:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "# Run experiments for different imbalance methods\n",
    "imbalance_methods = ['class_weights', 'oversampling', 'adasyn', 'undersampling', 'smote_enn']\n",
    "\n",
    "for method in imbalance_methods:\n",
    "    run_imbalanced_experiment(method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
